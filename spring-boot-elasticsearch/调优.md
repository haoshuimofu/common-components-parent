#写
总结（可能的最佳实践）
通过解决这几个问题，可以对ES集群配置和使用有个大概的最佳实践
1. 尽量将多的单次请求合并为bulk 操作
2. 对实时性要求不高的索引refresh_interval调整为30s
3. 对文档丢失的关注度不高，或者有定期补偿机制的可以将index.translog.sync_interval 设置为60S index.translog.durability设置为async，以及索引不多的情况下将index.translog.flush_threshold_size调整为1GB
4. merge.policy.max_merged_segment调整为1GB，降低大数据segment参与merge segment操作
5. 不要对_id进行排序或者聚合操作
6. 不需要分词的字段不要设置为text，不必要的字段可以不需要索引
7. 减少delete_by_query的使用
8. 业务代码对ES频繁写操作要进行限流削峰
9. number_of_replica设置为1即可，2备份会消耗过多内存
10. 主分片要尽量分布在不同节点。

#force merge
使用Elasticsearch REST API
通过发送HTTP POST请求到_forcemerge端点，可以执行force_merge操作。基本语法如下：

curl -X POST "http://localhost:9200//_forcemerge?max_num_segments="
其中：

``：替换为你要执行force_merge操作的索引名称。
``（可选）：指定目标合并后的段数。如果不提供，Elasticsearch会尽可能地合并段。设置合理的值有助于控制合并过程的资源消耗。
例如，对名为my_index的索引执行force_merge，将其段数减少到1：

curl -X POST "http://localhost:9200/my_index/_forcemerge?max_num_segments=1"
使用Elasticsearch客户端库
如果你使用的是Elasticsearch官方提供的客户端库（如Java、Python、JavaScript等），可以通过相应的方法调用来执行force_merge操作。下面以Python Elasticsearch客户端为例：

from elasticsearch import Elasticsearch

es = Elasticsearch()

# 对my_index执行force_merge，目标段数为1
es.indices.forcemerge(index="my_index", max_num_segments=1)
请查阅你所使用的客户端库的官方文档，了解如何使用对应的API方法来执行force_merge操作。

注意事项
资源消耗：force_merge操作可能会占用大量CPU、内存和磁盘I/O资源，尤其是在处理大型索引时。在执行此操作前，应评估其对集群的影响，并在低峰时段执行，或者确保有足够的资源应对。

数据可用性：在合并过程中，索引可能暂时不可搜索或不可更新。对于生产环境，建议先将索引设置为只读模式，或者创建索引副本，以确保数据的可用性和完整性。

滚动重启：对于大型索引，可能需要进行滚动重启（rolling restart）以释放文件句柄（file handles）。在某些操作系统中，单个进程打开的文件数量有限制，合并大量段可能会超过这个限制。滚动重启可以避免这个问题。

自动合并：Elasticsearch默认有一个后台进程定期合并段。如果主要关注磁盘空间优化，而搜索性能影响不大，可以调整索引的index.merge.policy设置，让Elasticsearch更积极地自动合并段，而不是频繁手动执行force_merge。

总之，force_merge命令是Elasticsearch中用于优化索引段结构的重要工具，但在使用时需谨慎考虑其对资源消耗、数据可用性等方面的影响，并根据实际需求合理设置参数。